# ğŸ—£ï¸ Speechably

**Creating confidence through user-driven feedback.**  
Optimized to deliver professional speech advice â€” at no cost.  
Perfect for public speaking, everyday conversation, or confidence-building exercises.

---

## ğŸ” Overview

**Speechably** is an AI-powered accessibility tool that analyzes videos of users giving speeches or speaking naturally. It evaluates both **speech emotion** and **body language**, then generates personalized feedback using a large language model (LLM). The goal: help users overcome social anxiety, improve delivery, and speak with confidence.

---

## ğŸ¯ Key Features

- ğŸ¥ **Video Upload** â€“ Users upload a short video of themselves speaking.
- ğŸ”Š **Speech Emotion Recognition** â€“ Detects tone, mood, and speaking style using pre-trained models.
- ğŸ’ƒ **Body Language Analysis** â€“ Uses pose estimation to assess posture, gestures, and confidence cues.
- ğŸ§  **AI-Powered Feedback** â€“ LLM-generated insights and tips to improve delivery and presence.
- ğŸŒ **Streamlit Interface** â€“ Clean, minimal UI for easy interaction and visualization.

---

## ğŸ—‚ï¸ Project Structure
```bash
speechably/
â”œâ”€â”€ app/                     # Frontend logic (Streamlit)
â”‚   â”œâ”€â”€ main.py              # Entry point for your web app
â”‚   â””â”€â”€ components/          # Reusable UI components if needed
â”‚
â”œâ”€â”€ backend/                 # Core processing logic
â”‚   â”œâ”€â”€ video_processor.py   # Extract frames, audio
â”‚   â”œâ”€â”€ emotion_model.py     # Run speech emotion recognition
â”‚   â”œâ”€â”€ pose_estimator.py    # Use MediaPipe or OpenPose
â”‚   â”œâ”€â”€ feedback_engine.py   # Feedback generation via LLM or rule-based
â”‚   â””â”€â”€ utils.py             # Shared utilities (e.g., file handling)
â”‚
â”œâ”€â”€ models/                  # Store downloaded/pretrained models
â”‚   â”œâ”€â”€ emotion/             
â”‚   â””â”€â”€ body_language/
â”‚
â”œâ”€â”€ data/                    # Sample videos and test inputs
â”‚   â”œâ”€â”€ test_video.mp4       
â”‚   â””â”€â”€ extracted_audio.wav
â”‚
â”œâ”€â”€ output/                  # Processed outputs and logs
â”‚   â”œâ”€â”€ feedback.json        
â”‚   â”œâ”€â”€ plots/               # Emotion timeline plots
â”‚   â””â”€â”€ debug_logs.txt
â”‚
â”œâ”€â”€ requirements.txt         # Python deps
â”œâ”€â”€ .env                     # API keys (Gemini)
â””â”€â”€ README.md                # Project overview
```


---

## âš™ï¸ Tech Stack

- **Python**
- **Streamlit** â€“ Frontend
- **MoviePy** â€“ Video + audio extraction
- **Kaggle / Hugging Face** â€“ Pre-trained Speech Emotion Models
- **MediaPipe** â€“ Pose & gesture analysis
- **Hugging Face** â€“ LLM Integration
- **Plotly** â€“ Optional feedback visualization

---

## ğŸš€ Getting Started

1. **Clone the repo**
   ```bash
   git clone https://github.com/your-username/speechably.git
   cd speechably

2. **Install Dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Create a .env file in the root directory and add your API key**
   ```bash
   GEMINI_API_KEY=your_key_here
   ```

4. **Run the program**
   ```bash
   cd app
   streamlit run main.py
   ```

